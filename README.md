# awesome-rl-algorithms
## Policy Optimization
- ICLR 2019, CEM-RL: Combining evolutionary and gradient-based methods for policy search. [Paper](https://arxiv.org/abs/1810.01222).
## Dynamic Programming
### SAC line of work
- ICML 2024 (Oral), ACE : Off-Policy Actor-Critic with Causality-Aware Entropy Regularization. [Paper](https://arxiv.org/abs/2402.14528).
### Others
- arXiv 2019, Towards Characterizing Divergence in Deep Q-Learning. [Paper](https://arxiv.org/abs/1903.08894).
- ICLR 2025, Towards General-Purpose Model-Free Reinforcement Learning. [Paper](https://arxiv.org/abs/2501.16142).Model-based representations for Q-learning.
- arXiv 2025.02, Value-Based Deep RL Scales Predictably. [Paper](https://arxiv.org/abs/2502.04327).
## Model-based
### TDMPC line of work
- arXiv 2025.02, TD-M(PC)2: Improving Temporal Difference MPC Through Policy Constraint. [Website](https://darthutopian.github.io/tdmpc_square/).
- ICLR 2025, Bootstrapped Model Predictive Control. [Paper](https://openreview.net/pdf?id=i7jAYFYDcM).
## Generalist RL
- arXiv 2024.12, RLDG: Robotic Generalist Policy Distillation via Reinforcement Learning. [Website](https://generalist-distillation.github.io/). [Paper](https://arxiv.org/abs/2412.09858).
## Offline RL
- ICML 2023, Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning. [Paper](https://arxiv.org/abs/2310.20587). [Code](https://github.com/srzer/LaMo-2023).
## Application
- arXiv 2025.01, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning. [Paper](https://arxiv.org/abs/2501.12948). [Code](https://github.com/huggingface/open-r1).
